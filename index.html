<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconocimiento Facial</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 20px;
        }
        .container {
            display: flex;
            gap: 20px;
        }
        video, canvas {
            width: 400px;
            height: 300px;
            border: 2px solid #333;
        }
        #result {
            margin-top: 20px;
            font-size: 20px;
        }
        button {
            margin-top: 10px;
            padding: 10px 20px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <h1>Prueba de Reconocimiento Facial</h1>
    <div class="container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="referenceCanvas"></canvas>
    </div>
    <input type="file" id="fileInput" accept="image/*">
    <button id="startCamera">Iniciar Cámara</button>
    <div id="result"></div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        const video = document.getElementById('webcam');
        const referenceCanvas = document.getElementById('referenceCanvas');
        const fileInput = document.getElementById('fileInput');
        const resultDiv = document.getElementById('result');
        let referenceDescriptor;

        // Cargar modelos de face-api.js
        async function loadModels() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        }

        // Cargar imagen de referencia
        fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            const img = await faceapi.bufferToImage(file);
            referenceCanvas.getContext('2d').drawImage(img, 0, 0, 400, 300);
            
            const detection = await faceapi
                .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceDescriptor();
            
            if (detection) {
                referenceDescriptor = detection.descriptor;
                resultDiv.textContent = "Imagen de referencia cargada. Inicia la cámara.";
            } else {
                resultDiv.textContent = "No se detectó un rostro en la imagen de referencia.";
            }
        });

        // Iniciar cámara
        document.getElementById('startCamera').addEventListener('click', async () => {
            const stream = await navigator.mediaDevices.getUser Media({ video: {} });
            video.srcObject = stream;

            // Comparar en tiempo real
            setInterval(async () => {
                if (!referenceDescriptor) return;

                const detection = await faceapi
                    .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detection) {
                    const distance = faceapi.euclideanDistance(referenceDescriptor, detection.descriptor);
                    const similarity = Math.round((1 - distance) * 100);
                    resultDiv.textContent = `Similitud: ${similarity}%`;

                    if (distance < 0.6) {
                        resultDiv.textContent += " - ✅ Coincidencia verificada";
                    } else {
                        resultDiv.textContent += " - ❌ No coincide";
                    }
                }
            }, 1000);
        });

        // Cargar modelos al inicio
        loadModels();
    </script>
</body>
</html>
